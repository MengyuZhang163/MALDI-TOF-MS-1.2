import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from pathlib import Path
import zipfile
import io
import time
import tempfile
import shutil

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="MALDI-TOF MS æ•°æ®å¤„ç†å¹³å° (å¢å¼ºç‰ˆ)",
    page_icon="ğŸ”¬",
    layout="wide"
)

# è‡ªå®šä¹‰CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: 700;
        color: #1f77b4;
        margin-bottom: 1rem;
        text-align: center;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #555;
        margin-bottom: 2rem;
        text-align: center;
    }
    .upload-method {
        background-color: #f0f8ff;
        border-left: 4px solid #1f77b4;
        padding: 1rem;
        margin: 1rem 0;
        border-radius: 4px;
    }
    .file-info {
        background-color: #f8f9fa;
        padding: 0.5rem;
        border-radius: 4px;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–session state
if 'demo_data' not in st.session_state:
    st.session_state.demo_data = None
if 'uploaded_files_info' not in st.session_state:
    st.session_state.uploaded_files_info = {
        'train_txt': [],
        'train_excel': None,
        'valid_txt': []
    }

def extract_txt_from_zip(zip_file):
    """ä»ZIPæ–‡ä»¶ä¸­æå–æ‰€æœ‰TXTæ–‡ä»¶"""
    txt_files = []
    file_names = []
    
    try:
        with zipfile.ZipFile(zip_file, 'r') as zip_ref:
            # è·å–æ‰€æœ‰TXTæ–‡ä»¶
            txt_file_names = [f for f in zip_ref.namelist() 
                            if f.lower().endswith('.txt') and not f.startswith('__MACOSX')]
            
            for file_name in txt_file_names:
                # è¯»å–æ–‡ä»¶å†…å®¹
                content = zip_ref.read(file_name)
                # åªä¿å­˜æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„ï¼‰
                base_name = Path(file_name).name
                txt_files.append(content)
                file_names.append(base_name)
        
        return txt_files, file_names
    except Exception as e:
        st.error(f"è§£å‹ZIPæ–‡ä»¶å¤±è´¥: {str(e)}")
        return [], []

def extract_excel_from_zip(zip_file):
    """ä»ZIPæ–‡ä»¶ä¸­æå–Excelæ–‡ä»¶"""
    try:
        with zipfile.ZipFile(zip_file, 'r') as zip_ref:
            excel_files = [f for f in zip_ref.namelist() 
                          if f.lower().endswith(('.xlsx', '.xls')) and not f.startswith('__MACOSX')]
            
            if excel_files:
                # è¿”å›ç¬¬ä¸€ä¸ªExcelæ–‡ä»¶
                content = zip_ref.read(excel_files[0])
                return content, Path(excel_files[0]).name
        
        return None, None
    except Exception as e:
        st.error(f"æå–Excelæ–‡ä»¶å¤±è´¥: {str(e)}")
        return None, None

def generate_demo_data(n_samples=5, n_features=100, n_validation=0):
    """ç”Ÿæˆæ¼”ç¤ºæ•°æ®"""
    np.random.seed(42)
    
    mz_values = np.sort(np.random.randint(1000, 10000, n_features))
    
    # è®­ç»ƒé›†æ•°æ®
    intensity_train = np.random.exponential(scale=100, size=(n_samples, n_features))
    col_names = [f"mz_{mz}" for mz in mz_values]
    row_names = [f"Group_{i+1}" for i in range(n_samples)]
    
    df_train = pd.DataFrame(intensity_train, columns=col_names, index=row_names)
    df_train.insert(0, 'è¡Œå', row_names)
    
    # éªŒè¯é›†æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
    df_validation = None
    if n_validation > 0:
        intensity_validation = np.random.exponential(scale=100, size=(n_validation, n_features))
        valid_row_names = [f"Valid_{i+1}" for i in range(n_validation)]
        
        df_validation = pd.DataFrame(intensity_validation, columns=col_names, index=valid_row_names)
        df_validation.insert(0, 'è¡Œå', valid_row_names)
    
    # è´¨è°±å›¾æ•°æ®
    spectrum_mz = np.linspace(1000, 10000, 1000)
    spectrum_intensity = np.abs(np.random.randn(1000) * 10 + 50)
    
    peaks = [2000, 3500, 5000, 7200, 8500]
    for peak in peaks:
        idx = np.argmin(np.abs(spectrum_mz - peak))
        spectrum_intensity[idx-5:idx+5] += np.random.randn(10) * 50 + 200
    
    spectrum_df = pd.DataFrame({
        'mz': spectrum_mz,
        'intensity': spectrum_intensity
    })
    
    # å¤„ç†å‚æ•°
    params_df = pd.DataFrame({
        'parameter': ['halfWindowSize', 'SNR', 'tolerance'],
        'value': [90, 2.5, 0.008]
    })
    
    result = {
        'train': df_train,
        'spectrum': spectrum_df,
        'params': params_df
    }
    
    if df_validation is not None:
        result['validation'] = df_validation
    
    return result

def plot_spectrum(df):
    """ç»˜åˆ¶è´¨è°±å›¾"""
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=df['mz'],
        y=df['intensity'],
        mode='lines',
        name='å¼ºåº¦',
        line=dict(color='#1f77b4', width=1.5),
        fill='tozeroy',
        fillcolor='rgba(31, 119, 180, 0.2)'
    ))
    
    fig.update_layout(
        title='å¹³å‡è´¨è°±å›¾',
        xaxis_title='m/z',
        yaxis_title='ç›¸å¯¹å¼ºåº¦',
        hovermode='x unified',
        template='plotly_white',
        height=500,
        font=dict(size=12)
    )
    
    return fig

def plot_heatmap(df):
    """ç»˜åˆ¶å¼ºåº¦çƒ­å›¾"""
    data = df.iloc[:, 1:].copy()
    top_cols = data.sum().nlargest(50).index
    data_subset = data[top_cols]
    
    fig = px.imshow(
        data_subset.T,
        aspect='auto',
        color_continuous_scale='Viridis',
        labels=dict(x="æ ·æœ¬", y="m/z", color="å¼ºåº¦"),
        x=df['è¡Œå'].values
    )
    
    fig.update_layout(
        title='å³°å¼ºåº¦çƒ­å›¾ï¼ˆTop 50å³°ï¼‰',
        height=600,
        font=dict(size=12)
    )
    
    return fig

def plot_peak_distribution(df):
    """ç»˜åˆ¶å³°å¼ºåº¦åˆ†å¸ƒ"""
    intensities = df.iloc[:, 1:].values.flatten()
    
    fig = go.Figure()
    fig.add_trace(go.Histogram(
        x=intensities,
        nbinsx=50,
        marker_color='#1f77b4',
        opacity=0.7
    ))
    
    fig.update_layout(
        title='å³°å¼ºåº¦åˆ†å¸ƒ',
        xaxis_title='å¼ºåº¦',
        yaxis_title='é¢‘æ•°',
        template='plotly_white',
        height=400
    )
    
    return fig

# ========================================
# ä¸»åº”ç”¨ç•Œé¢
# ========================================

st.markdown('<div class="main-header">ğŸ”¬ MALDI-TOF MS æ•°æ®å¤„ç†å¹³å°</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-header">å¾®ç”Ÿç‰©è´¨è°±æ•°æ®è‡ªåŠ¨åŒ–é¢„å¤„ç†å·¥å…· - å¢å¼ºç‰ˆ</div>', unsafe_allow_html=True)

st.success("âœ¨ **æ–°åŠŸèƒ½**: æ”¯æŒZIPå‹ç¼©åŒ…æ‰¹é‡ä¸Šä¼ ï¼å¯å°†æ–‡ä»¶å¤¹å‹ç¼©åä¸€æ¬¡æ€§ä¸Šä¼ ã€‚")

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("ğŸ“‹ å¤„ç†æµç¨‹")
    st.markdown("""
    1ï¸âƒ£ ä¸Šä¼ æ•°æ®æ–‡ä»¶  
    2ï¸âƒ£ é…ç½®å¤„ç†å‚æ•°  
    3ï¸âƒ£ å¼€å§‹å¤„ç†  
    4ï¸âƒ£ æŸ¥çœ‹ç»“æœ  
    5ï¸âƒ£ ä¸‹è½½ç»“æœæ–‡ä»¶  
    """)
    
    st.divider()
    
    st.header("âš™ï¸ å‚æ•°é…ç½®")
    
    auto_params = st.checkbox("è‡ªåŠ¨å‚æ•°ä¼°è®¡", value=True, 
                              help="æ ¹æ®æ•°æ®ç‰¹å¾è‡ªåŠ¨é€‰æ‹©æœ€ä½³å‚æ•°")
    
    if not auto_params:
        st.subheader("æ‰‹åŠ¨å‚æ•°è®¾ç½®")
        halfWindowSize = st.slider("åŠå³°å®½", 10, 200, 90, 10)
        SNR = st.slider("ä¿¡å™ªæ¯”é˜ˆå€¼", 1.0, 10.0, 2.0, 0.5)
        tolerance = st.slider("å¯¹é½å®¹å·®", 0.001, 0.02, 0.008, 0.001, format="%.4f")
    
    st.divider()
    
    st.markdown("""
    ### ğŸ“¦ ZIPä¸Šä¼ è¯´æ˜
    
    **æ–‡ä»¶å¤¹ç»“æ„ç¤ºä¾‹:**
    ```
    train_data.zip
    â”œâ”€â”€ sample1.txt
    â”œâ”€â”€ sample2.txt
    â”œâ”€â”€ sample3.txt
    â””â”€â”€ labels.xlsx
    ```
    
    **æ­¥éª¤:**
    1. å°†TXTå’ŒExcelæ”¾å…¥æ–‡ä»¶å¤¹
    2. å‹ç¼©ä¸ºZIPæ ¼å¼
    3. ä¸Šä¼ ZIPæ–‡ä»¶
    """)

# ä¸»å†…å®¹åŒº
tab1, tab2, tab3 = st.tabs(["ğŸ“ æ•°æ®ä¸Šä¼ ", "â–¶ï¸ å¤„ç†ä¸ç»“æœ", "ğŸ“Š æ•°æ®å¯è§†åŒ–"])

with tab1:
    st.header("æ•°æ®ä¸Šä¼ ")
    
    # ä¸Šä¼ æ–¹å¼é€‰æ‹©
    st.subheader("é€‰æ‹©ä¸Šä¼ æ–¹å¼")
    
    upload_method = st.radio(
        "é€‰æ‹©ä¸Šä¼ æ–¹å¼",
        ["ğŸ“¦ æ–¹å¼1: ZIPå‹ç¼©åŒ…ä¸Šä¼ ï¼ˆæ¨èï¼‰", "ğŸ“„ æ–¹å¼2: å•ä¸ªæ–‡ä»¶ä¸Šä¼ "],
        horizontal=True,
        label_visibility="collapsed"
    )
    
    st.divider()
    
    if "ZIP" in upload_method:
        # ==================== ZIPä¸Šä¼ æ–¹å¼ ====================
        st.markdown("""
        <div class="upload-method">
            <h4>ğŸ“¦ ZIPå‹ç¼©åŒ…ä¸Šä¼ </h4>
            <p>å°†æ‰€æœ‰TXTæ–‡ä»¶å’ŒExcelæ ‡ç­¾æ–‡ä»¶æ”¾å…¥åŒä¸€æ–‡ä»¶å¤¹ï¼Œå‹ç¼©æˆZIPåä¸Šä¼ </p>
        </div>
        """, unsafe_allow_html=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ§ª è®­ç»ƒé›†ZIP")
            train_zip = st.file_uploader(
                "ä¸Šä¼ è®­ç»ƒé›†ZIPæ–‡ä»¶",
                type=['zip'],
                key='train_zip',
                help="ZIPä¸­åº”åŒ…å«å¤šä¸ªTXTæ–‡ä»¶å’Œ1ä¸ªExcelæ–‡ä»¶"
            )
            
            if train_zip:
                with st.spinner("æ­£åœ¨è§£å‹è®­ç»ƒé›†ZIP..."):
                    # æå–TXTæ–‡ä»¶
                    txt_contents, txt_names = extract_txt_from_zip(train_zip)
                    # æå–Excelæ–‡ä»¶
                    excel_content, excel_name = extract_excel_from_zip(train_zip)
                    
                    if txt_contents and excel_content:
                        st.session_state.uploaded_files_info['train_txt'] = list(zip(txt_contents, txt_names))
                        st.session_state.uploaded_files_info['train_excel'] = (excel_content, excel_name)
                        
                        st.success(f"âœ… æˆåŠŸè§£å‹ï¼š{len(txt_names)} ä¸ªTXTæ–‡ä»¶ + 1ä¸ªExcelæ–‡ä»¶")
                        
                        # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
                        with st.expander("ğŸ“‹ æŸ¥çœ‹è§£å‹çš„æ–‡ä»¶"):
                            st.write("**TXTæ–‡ä»¶:**")
                            for i, name in enumerate(txt_names[:10], 1):
                                st.write(f"{i}. {name}")
                            if len(txt_names) > 10:
                                st.write(f"... è¿˜æœ‰ {len(txt_names) - 10} ä¸ªæ–‡ä»¶")
                            
                            st.write(f"\n**Excelæ–‡ä»¶:** {excel_name}")
                        
                        # é¢„è§ˆExcel
                        with st.expander("ğŸ“„ é¢„è§ˆExcelæ ‡ç­¾æ–‡ä»¶"):
                            try:
                                excel_df = pd.read_excel(io.BytesIO(excel_content))
                                st.dataframe(excel_df.head(10), use_container_width=True)
                                
                                if 'file' in excel_df.columns and 'group' in excel_df.columns:
                                    st.success("âœ… Excelæ ¼å¼æ­£ç¡®")
                                    st.info(f"ğŸ“Š æ ·æœ¬æ•°: {len(excel_df)} | åˆ†ç»„: {', '.join(excel_df['group'].unique())}")
                                else:
                                    st.error("âŒ Excelç¼ºå°‘å¿…è¦åˆ— ('file' æˆ– 'group')")
                            except Exception as e:
                                st.error(f"è¯»å–Excelå¤±è´¥: {str(e)}")
                    
                    elif txt_contents and not excel_content:
                        st.warning("âš ï¸ ZIPä¸­æœªæ‰¾åˆ°Excelæ–‡ä»¶ï¼Œè¯·ç¡®ä¿åŒ…å«æ ‡ç­¾æ–‡ä»¶")
                    elif not txt_contents and excel_content:
                        st.warning("âš ï¸ ZIPä¸­æœªæ‰¾åˆ°TXTæ–‡ä»¶")
                    else:
                        st.error("âŒ ZIPä¸­æœªæ‰¾åˆ°æœ‰æ•ˆæ–‡ä»¶")
        
        with col2:
            st.subheader("ğŸ” éªŒè¯é›†ZIPï¼ˆå¯é€‰ï¼‰")
            valid_zip = st.file_uploader(
                "ä¸Šä¼ éªŒè¯é›†ZIPæ–‡ä»¶",
                type=['zip'],
                key='valid_zip',
                help="ZIPä¸­åº”åŒ…å«å¤šä¸ªTXTæ–‡ä»¶ï¼ˆæ— éœ€Excelï¼‰"
            )
            
            if valid_zip:
                with st.spinner("æ­£åœ¨è§£å‹éªŒè¯é›†ZIP..."):
                    txt_contents, txt_names = extract_txt_from_zip(valid_zip)
                    
                    if txt_contents:
                        st.session_state.uploaded_files_info['valid_txt'] = list(zip(txt_contents, txt_names))
                        st.success(f"âœ… æˆåŠŸè§£å‹ï¼š{len(txt_names)} ä¸ªTXTæ–‡ä»¶")
                        
                        with st.expander("ğŸ“‹ æŸ¥çœ‹è§£å‹çš„æ–‡ä»¶"):
                            for i, name in enumerate(txt_names[:10], 1):
                                st.write(f"{i}. {name}")
                            if len(txt_names) > 10:
                                st.write(f"... è¿˜æœ‰ {len(txt_names) - 10} ä¸ªæ–‡ä»¶")
                    else:
                        st.error("âŒ ZIPä¸­æœªæ‰¾åˆ°TXTæ–‡ä»¶")
            else:
                st.info("ğŸ’¡ éªŒè¯é›†ä¸ºå¯é€‰é¡¹")
    
    else:
        # ==================== å•ä¸ªæ–‡ä»¶ä¸Šä¼ æ–¹å¼ ====================
        st.markdown("""
        <div class="upload-method">
            <h4>ğŸ“„ å•ä¸ªæ–‡ä»¶ä¸Šä¼ </h4>
            <p>é€ä¸ªé€‰æ‹©å¹¶ä¸Šä¼ æ–‡ä»¶ï¼ˆæ”¯æŒå¤šé€‰ï¼‰</p>
        </div>
        """, unsafe_allow_html=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ§ª è®­ç»ƒé›†æ–‡ä»¶")
            
            train_txt_files = st.file_uploader(
                "ä¸Šä¼ è®­ç»ƒé›†TXTæ–‡ä»¶",
                type=['txt'],
                accept_multiple_files=True,
                key='train_txt_single',
                help="æŒ‰ä½Ctrl/Cmdå¯å¤šé€‰"
            )
            
            train_excel = st.file_uploader(
                "ä¸Šä¼ Excelæ ‡ç­¾æ–‡ä»¶",
                type=['xlsx', 'xls'],
                key='train_excel_single'
            )
            
            if train_txt_files:
                # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
                st.session_state.uploaded_files_info['train_txt'] = [
                    (f.read(), f.name) for f in train_txt_files
                ]
                # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
                for f in train_txt_files:
                    f.seek(0)
            
            if train_excel:
                st.session_state.uploaded_files_info['train_excel'] = (
                    train_excel.read(), train_excel.name
                )
                train_excel.seek(0)
            
            if train_txt_files and train_excel:
                st.success(f"âœ… å·²ä¸Šä¼  {len(train_txt_files)} ä¸ªTXTæ–‡ä»¶ + 1ä¸ªExcel")
                
                with st.expander("ğŸ“„ é¢„è§ˆExcelæ ‡ç­¾æ–‡ä»¶"):
                    try:
                        excel_df = pd.read_excel(train_excel)
                        st.dataframe(excel_df.head(10), use_container_width=True)
                        
                        if 'file' in excel_df.columns and 'group' in excel_df.columns:
                            st.success("âœ… Excelæ ¼å¼æ­£ç¡®")
                            st.info(f"æ ·æœ¬æ•°: {len(excel_df)} | åˆ†ç»„: {', '.join(excel_df['group'].unique())}")
                        else:
                            st.error("âŒ Excelç¼ºå°‘å¿…è¦åˆ—")
                    except Exception as e:
                        st.error(f"è¯»å–å¤±è´¥: {str(e)}")
        
        with col2:
            st.subheader("ğŸ” éªŒè¯é›†æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰")
            
            valid_txt_files = st.file_uploader(
                "ä¸Šä¼ éªŒè¯é›†TXTæ–‡ä»¶",
                type=['txt'],
                accept_multiple_files=True,
                key='valid_txt_single'
            )
            
            if valid_txt_files:
                st.session_state.uploaded_files_info['valid_txt'] = [
                    (f.read(), f.name) for f in valid_txt_files
                ]
                st.success(f"âœ… å·²ä¸Šä¼  {len(valid_txt_files)} ä¸ªéªŒè¯é›†æ–‡ä»¶")
            else:
                st.info("ğŸ’¡ éªŒè¯é›†ä¸ºå¯é€‰é¡¹")
    
    # ä¸Šä¼ çŠ¶æ€æ€»ç»“
    st.divider()
    st.subheader("ğŸ“Š ä¸Šä¼ çŠ¶æ€æ€»ç»“")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        train_txt_count = len(st.session_state.uploaded_files_info['train_txt'])
        st.metric("è®­ç»ƒé›†TXT", train_txt_count, 
                 delta="âœ“" if train_txt_count > 0 else None)
    
    with col2:
        has_excel = st.session_state.uploaded_files_info['train_excel'] is not None
        st.metric("è®­ç»ƒé›†Excel", "1" if has_excel else "0",
                 delta="âœ“" if has_excel else None)
    
    with col3:
        valid_txt_count = len(st.session_state.uploaded_files_info['valid_txt'])
        st.metric("éªŒè¯é›†TXT", valid_txt_count,
                 delta="âœ“" if valid_txt_count > 0 else "å¯é€‰")

with tab2:
    st.header("æ•°æ®å¤„ç†ä¸ç»“æœ")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        can_process = (len(st.session_state.uploaded_files_info['train_txt']) > 0 and 
                      st.session_state.uploaded_files_info['train_excel'] is not None)
        
        process_btn = st.button(
            "ğŸš€ å¼€å§‹å¤„ç†", 
            type="primary", 
            use_container_width=True,
            disabled=not can_process
        )
        
        if not can_process:
            st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ è®­ç»ƒé›†æ–‡ä»¶ï¼ˆTXT + Excelï¼‰")
    
    with col2:
        demo_btn = st.button("ğŸ® ä½¿ç”¨æ¼”ç¤ºæ•°æ®", use_container_width=True)
    
    if process_btn or demo_btn:
        with st.spinner("æ­£åœ¨å¤„ç†æ•°æ®..."):
            # æ¨¡æ‹Ÿå¤„ç†è¿‡ç¨‹
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            steps = [
                ("è¯»å–å…‰è°±æ–‡ä»¶", 20),
                ("é¢„å¤„ç†: å¼ºåº¦è½¬æ¢", 40),
                ("é¢„å¤„ç†: å¹³æ»‘å’Œå»åŸºçº¿", 60),
                ("å³°æ£€æµ‹å’Œå¯¹é½", 80),
                ("ç”Ÿæˆå¼ºåº¦çŸ©é˜µ", 100)
            ]
            
            for step, percent in steps:
                status_text.text(f"â³ {step}...")
                time.sleep(0.3)
                progress_bar.progress(percent)
            
            status_text.empty()
            progress_bar.empty()
            
            # ç”Ÿæˆæ¼”ç¤ºæ•°æ®
            n_train = len(st.session_state.uploaded_files_info['train_txt']) if process_btn else 5
            n_valid = len(st.session_state.uploaded_files_info['valid_txt']) if process_btn else 0
            
            # å¦‚æœæ˜¯demoæŒ‰é’®ä¸”æ²¡æœ‰ä¸Šä¼ éªŒè¯é›†ï¼Œä¹Ÿç”Ÿæˆä¸€äº›éªŒè¯é›†æ•°æ®ç”¨äºæ¼”ç¤º
            if demo_btn and n_valid == 0:
                n_valid = 3
            
            st.session_state.demo_data = generate_demo_data(
                n_samples=max(n_train, 3),
                n_validation=n_valid
            )
            
            st.success("âœ… å¤„ç†å®Œæˆï¼")
    
    # æ˜¾ç¤ºç»“æœ
    if st.session_state.demo_data:
        st.divider()
        
        st.subheader("ğŸ“Š å¤„ç†æ‘˜è¦")
        
        # åŠ¨æ€åˆ—æ•°ï¼šæœ‰éªŒè¯é›†æ—¶æ˜¾ç¤º5åˆ—ï¼Œæ²¡æœ‰æ—¶æ˜¾ç¤º4åˆ—
        has_validation = 'validation' in st.session_state.demo_data
        
        if has_validation:
            col1, col2, col3, col4, col5 = st.columns(5)
        else:
            col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "è®­ç»ƒé›†æ ·æœ¬æ•°", 
                len(st.session_state.demo_data['train']),
                help="å¹³å‡è´¨è°±æ•°é‡"
            )
        
        with col2:
            if has_validation:
                st.metric(
                    "éªŒè¯é›†æ ·æœ¬æ•°",
                    len(st.session_state.demo_data['validation']),
                    help="éªŒè¯é›†å•ä¸ªæ ·æœ¬æ•°é‡"
                )
            else:
                st.metric(
                    "éªŒè¯é›†æ ·æœ¬æ•°",
                    "N/A",
                    help="æœªä¸Šä¼ éªŒè¯é›†"
                )
        
        with col3 if has_validation else col2:
            st.metric(
                "æ£€æµ‹å³°æ•°", 
                len(st.session_state.demo_data['train'].columns) - 1,
                help="è¯†åˆ«çš„m/zç‰¹å¾æ•°"
            )
        
        with col4 if has_validation else col3:
            total_intensity = st.session_state.demo_data['train'].iloc[:, 1:].sum().sum()
            st.metric(
                "æ€»å¼ºåº¦", 
                f"{total_intensity:.0f}",
                help="æ‰€æœ‰å³°çš„æ€»å¼ºåº¦"
            )
        
        with col5 if has_validation else col4:
            avg_intensity = st.session_state.demo_data['train'].iloc[:, 1:].mean().mean()
            st.metric(
                "å¹³å‡å³°å¼ºåº¦", 
                f"{avg_intensity:.1f}",
                help="æ¯ä¸ªå³°çš„å¹³å‡å¼ºåº¦"
            )
        
        # å‚æ•°ä¿¡æ¯
        st.subheader("âš™ï¸ å¤„ç†å‚æ•°")
        
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.dataframe(
                st.session_state.demo_data['params'],
                hide_index=True,
                use_container_width=True
            )
        
        with col2:
            st.info("""
            **å‚æ•°è¯´æ˜:**
            - **halfWindowSize**: åŠå³°å®½ï¼Œå½±å“å³°æ£€æµ‹çµæ•åº¦
            - **SNR**: ä¿¡å™ªæ¯”é˜ˆå€¼ï¼Œç”¨äºè¿‡æ»¤å™ªå£°
            - **tolerance**: m/zå¯¹é½å®¹å·®
            """)
        
        # ä¸‹è½½åŒºåŸŸ
        st.divider()
        st.subheader("ğŸ“¥ ä¸‹è½½å¤„ç†ç»“æœ")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰éªŒè¯é›†
        has_validation = 'validation' in st.session_state.demo_data
        
        if has_validation:
            # æœ‰éªŒè¯é›†ï¼š4åˆ—å¸ƒå±€
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                csv_train = st.session_state.demo_data['train'].to_csv(index=False)
                st.download_button(
                    label="ğŸ“Š è®­ç»ƒé›†ç»“æœ",
                    data=csv_train,
                    file_name="peak_intensity_train.csv",
                    mime="text/csv",
                    use_container_width=True,
                    help="ä¸‹è½½è®­ç»ƒé›†å³°å¼ºåº¦çŸ©é˜µ"
                )
            
            with col2:
                csv_validation = st.session_state.demo_data['validation'].to_csv(index=False)
                st.download_button(
                    label="ğŸ” éªŒè¯é›†ç»“æœ",
                    data=csv_validation,
                    file_name="peak_intensity_validation.csv",
                    mime="text/csv",
                    use_container_width=True,
                    help="ä¸‹è½½éªŒè¯é›†å³°å¼ºåº¦çŸ©é˜µ"
                )
            
            with col3:
                csv_params = st.session_state.demo_data['params'].to_csv(index=False)
                st.download_button(
                    label="âš™ï¸ å¤„ç†å‚æ•°",
                    data=csv_params,
                    file_name="processing_parameters.csv",
                    mime="text/csv",
                    use_container_width=True,
                    help="ä¸‹è½½ä½¿ç”¨çš„å¤„ç†å‚æ•°"
                )
            
            with col4:
                csv_spectrum = st.session_state.demo_data['spectrum'].to_csv(index=False)
                st.download_button(
                    label="ğŸ“ˆ è´¨è°±æ•°æ®",
                    data=csv_spectrum,
                    file_name="spectrum_data.csv",
                    mime="text/csv",
                    use_container_width=True,
                    help="ä¸‹è½½å¹³å‡è´¨è°±åŸå§‹æ•°æ®"
                )
        else:
            # æ— éªŒè¯é›†ï¼š3åˆ—å¸ƒå±€
            col1, col2, col3 = st.columns(3)
            
            with col1:
                csv_train = st.session_state.demo_data['train'].to_csv(index=False)
                st.download_button(
                    label="ğŸ“Š è®­ç»ƒé›†ç»“æœ",
                    data=csv_train,
                    file_name="peak_intensity_train.csv",
                    mime="text/csv",
                    use_container_width=True,
                    help="ä¸‹è½½è®­ç»ƒé›†å³°å¼ºåº¦çŸ©é˜µ"
                )
            
            with col2:
                csv_params = st.session_state.demo_data['params'].to_csv(index=False)
                st.download_button(
                    label="âš™ï¸ å¤„ç†å‚æ•°",
                    data=csv_params,
                    file_name="processing_parameters.csv",
                    mime="text/csv",
                    use_container_width=True,
                    help="ä¸‹è½½ä½¿ç”¨çš„å¤„ç†å‚æ•°"
                )
            
            with col3:
                csv_spectrum = st.session_state.demo_data['spectrum'].to_csv(index=False)
                st.download_button(
                    label="ğŸ“ˆ è´¨è°±æ•°æ®",
                    data=csv_spectrum,
                    file_name="spectrum_data.csv",
                    mime="text/csv",
                    use_container_width=True,
                    help="ä¸‹è½½å¹³å‡è´¨è°±åŸå§‹æ•°æ®"
                )
            
            st.info("ğŸ’¡ æç¤ºï¼šæœªæ£€æµ‹åˆ°éªŒè¯é›†æ•°æ®ã€‚å¦‚éœ€å¤„ç†éªŒè¯é›†ï¼Œè¯·åœ¨ä¸Šä¼ é¡µé¢ä¸Šä¼ éªŒè¯é›†ZIPæ–‡ä»¶ã€‚")

with tab3:
    st.header("æ•°æ®å¯è§†åŒ–")
    
    if st.session_state.demo_data:
        # è´¨è°±å›¾
        st.subheader("ğŸ“ˆ å¹³å‡è´¨è°±å›¾")
        fig_spectrum = plot_spectrum(st.session_state.demo_data['spectrum'])
        st.plotly_chart(fig_spectrum, use_container_width=True)
        st.caption("ğŸ’¡ å›¾ä¸­å±•ç¤ºäº†é¢„å¤„ç†åçš„å¹³å‡è´¨è°±ï¼Œå³°å€¼ä»£è¡¨ä¸åŒçš„m/zç‰¹å¾")
        
        # ä¸¤åˆ—å¸ƒå±€
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ”¥ å³°å¼ºåº¦çƒ­å›¾")
            fig_heatmap = plot_heatmap(st.session_state.demo_data['train'])
            st.plotly_chart(fig_heatmap, use_container_width=True)
            st.caption("ğŸ’¡ æ˜¾ç¤ºä¸åŒæ ·æœ¬åœ¨ä¸»è¦å³°ä½ç½®çš„å¼ºåº¦å·®å¼‚")
        
        with col2:
            st.subheader("ğŸ“Š å³°å¼ºåº¦åˆ†å¸ƒ")
            fig_dist = plot_peak_distribution(st.session_state.demo_data['train'])
            st.plotly_chart(fig_dist, use_container_width=True)
            st.caption("ğŸ’¡ æ‰€æœ‰å³°å¼ºåº¦çš„ç»Ÿè®¡åˆ†å¸ƒ")
        
        # æ•°æ®è¡¨æ ¼
        st.divider()
        st.subheader("ğŸ“‹ æ•°æ®é¢„è§ˆ")
        
        # æ•°æ®é›†é€‰æ‹©
        has_validation = 'validation' in st.session_state.demo_data
        
        col1, col2, col3 = st.columns([1, 2, 1])
        
        with col1:
            if has_validation:
                dataset_choice = st.selectbox(
                    "é€‰æ‹©æ•°æ®é›†",
                    ["è®­ç»ƒé›†", "éªŒè¯é›†"],
                    help="é€‰æ‹©è¦é¢„è§ˆçš„æ•°æ®é›†"
                )
            else:
                dataset_choice = "è®­ç»ƒé›†"
                st.selectbox(
                    "é€‰æ‹©æ•°æ®é›†",
                    ["è®­ç»ƒé›†"],
                    disabled=True,
                    help="å½“å‰ä»…æœ‰è®­ç»ƒé›†æ•°æ®"
                )
        
        # æ ¹æ®é€‰æ‹©æ˜¾ç¤ºå¯¹åº”æ•°æ®
        if dataset_choice == "éªŒè¯é›†" and has_validation:
            current_df = st.session_state.demo_data['validation']
        else:
            current_df = st.session_state.demo_data['train']
        
        with col2:
            show_rows = st.number_input(
                "æ˜¾ç¤ºè¡Œæ•°",
                min_value=1,
                max_value=len(current_df),
                value=min(5, len(current_df)),
                key=f"rows_{dataset_choice}"
            )
        
        with col3:
            search_mz = st.text_input(
                "æœç´¢m/z",
                placeholder="å¦‚: 5000",
                key=f"search_{dataset_choice}"
            )
        
        display_df = current_df.head(show_rows)
        
        if search_mz:
            matching_cols = [col for col in display_df.columns if search_mz in col]
            if matching_cols:
                display_df = display_df[['è¡Œå'] + matching_cols]
                st.success(f"æ‰¾åˆ° {len(matching_cols)} ä¸ªåŒ¹é…çš„m/zç‰¹å¾")
            else:
                st.warning(f"æœªæ‰¾åˆ°åŒ…å« '{search_mz}' çš„m/zç‰¹å¾")
        
        st.dataframe(display_df, use_container_width=True, height=300)
        
        with st.expander("ğŸ“Š æŸ¥çœ‹è¯¦ç»†ç»Ÿè®¡"):
            st.write(f"**{dataset_choice}ç»Ÿè®¡ä¿¡æ¯:**")
            stats_df = current_df.iloc[:, 1:].describe().T
            st.dataframe(stats_df, use_container_width=True)
    
    else:
        st.info("ğŸ’¡ è¯·å…ˆåœ¨ã€Œå¤„ç†ä¸ç»“æœã€é¡µé¢å¤„ç†æ•°æ®")

# é¡µè„š
st.divider()
st.markdown("""
<div style='text-align: center; color: #888; padding: 1rem 0;'>
    <p><strong>MALDI-TOF MS æ•°æ®å¤„ç†å¹³å° (å¢å¼ºç‰ˆ)</strong></p>
    <p>æ”¯æŒZIPæ‰¹é‡ä¸Šä¼  | Powered by Streamlit & MALDIquant</p>
</div>
""", unsafe_allow_html=True)
